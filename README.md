# Detection of Diabetic Retinopathy

**Author:** Vishvas Ranjan, UM DAE Centre for Excellence in Basic Sciences, Mumbai  
**Competition:** Inter-INCI Entrepreneurial Summit (IIEâ€‘S) 2025 (IISER â€¢ NISER â€¢ CEBS â€¢ IISc) @ IISER Kolkata  
**Result:** 2nd Runnerâ€‘Up among teams of PhD students, with my team composed of masterâ€™sâ€‘level students  

---

## ðŸš€ Project Vision

This was an ideathonâ€‘style challenge: build a proofâ€‘ofâ€‘concept using only our existing skills to see if a â€œfromâ€‘scratchâ€ approach could yield promising results.  
> **Note:** Code quality and optimization are ongoing :â€” our current goal is to demonstrate that the idea works; domain experts can later refine and extend it.

---

## ðŸ“‹ Overview

We tackled diabetic retinopathy (DR) classification using clinicianâ€‘labeled retinal images. Key steps:

1. **Dataset & Objective**  
   - **Source:** Kaggle Diabetic Retinopathy Classification competition  
     (5â€‘level labels by clinicians)  
     https://www.kaggle.com/competitions/diabetic-retinopathy-classification-f1-score-4/data  
   - **Sample:** 2,200 images  
   - **Goal:** Train deep CNNs, measure performance via F1â€‘Score & accuracy, and handle class imbalance.

2. **Model Experiments (5â€‘Class)**  
   - Architectures: ResNet50, EfficientNetB4, DenseNet121  
   - Loss & Metrics: Focal Loss; track both accuracy and F1â€‘Score  
   - Class imbalance: LevelÂ 0 = 52% â†’ model easily fits majority but struggles on minority  
   - **Validation Accuracies:**  
     - ResNet50: 73%  
     - EfficientNetB4: 69%  
     - DenseNet121: 77%  
   - **After tuning (augments, classâ€‘weights): F1â€‘Scores on validation**  
     - ResNet50: 92  
     - EfficientNetB4: 77  
     - DenseNet121: 94  

3. **Binary Classification Approach**  
   - Merge labels: LevelÂ 0 â†’ ClassÂ 0; LevelsÂ 1â€“4 â†’ ClassÂ 1 (balanced classes)  
   - Model: DenseNet121  
   - **Results:**  
     - Training Acc.: 92%Â |Â Validation Acc.: 90%  
     - F1â€‘Scores: >â€¯90 (both train & val)  
   - **Loss Curves:**  
     - Training loss â†“ 0.20 â†’Â 0.00 over 25Â epochs  
     - Validation loss â†“ 0.15 â†’Â 0.05, closely tracking training â†’ minimal overfitting  

---

## ðŸŽ¯ Key Insights

- **DenseNet121** delivered the best balance of accuracy & F1, with smooth, stable training curves.  
- **F1â€‘Score** is the critical metric for imbalanced medical dataâ€”here it uncovers true performance beyond raw accuracy.  
- **Binary task** (healthy vs. DR) resolves extreme imbalance and yields robust, highâ€‘confidence results.  
- This work is **proofâ€‘ofâ€‘concept**â€”we invite ML experts to build on our pipeline.

---

## ðŸ“Š Slideâ€‘Ready Summary

- **Dataset & Objective:**  
  - 2,200 clinicianâ€‘labeled DR images (5 levels) from Kaggle  
  - Focus: F1â€‘Score & accuracy; address class imbalance  

- **5â€‘Class Experiments:**  
  - Models: ResNet50, EfficientNetB4, DenseNet121  
  - Validation Accuracies: 73% | 69% | 77%  
  - Tuned F1â€‘Scores: 92 | 77 | 93 â†’ DenseNet121 shines  

- **Preprocessing & Training:**  
  - 80/20 train/val split; Albumentations for augments  
  - Focal Loss + class weights  
  - Spiky training curves â†’ need robust augments  

- **Binary Classification:**  
  - LevelÂ 0 vs. LevelsÂ 1â€“4 â†’ balanced twoâ€‘class task  
  - DenseNet121 â†’ 92% train, 90% val acc; F1Â >â€¯90  

- **Loss Evolution:**  
  - Training loss: 0.20 â†’Â 0.00  
  - Validation loss: 0.15 â†’Â 0.05 (stable convergence)  

- **Conclusion:**  
  - Provides intuition, not a final model  
  - Encourages experts to iterate  
  - Highlights F1â€‘Scoreâ€™s importance in imbalanced medical datasets  

---

## ðŸ”— Dataset

- **Kaggle Diabetic Retinopathy Classification**  
  https://www.kaggle.com/competitions/diabetic-retinopathy-classification-f1-score-4/data

---

## ðŸ“– Next Steps

- Code cleanup & modularization  
- Hyperparameter sweeps & advanced augmentations  
- Integration of expertâ€‘built architectures and pipelines  

---

*Thanks for checking out our proofâ€‘ofâ€‘concept! We hope it sparks new ideas in DR detection.*  
